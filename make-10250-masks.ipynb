{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">\n",
    "(5), (6), (8) Below = things to check with Mihail!\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndescribe what function does\\n\\n@param file_name:\\n@param 2/...:\\n\\n@return:\\n\\n@throws: do this if throws an exception\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:\n",
    "# (1) Once the script is set in stone add this syntax to all of the function headers\"\n",
    "'''\n",
    "describe what function does\n",
    "\n",
    "@param file_name:\n",
    "@param 2/...:\n",
    "\n",
    "@return:\n",
    "\n",
    "@throws: do this if throws an exception\n",
    "'''\n",
    "# \n",
    "# (2) get rid of idx += 1 use enumerate instead\n",
    "#\n",
    "# (3) Use np.zeros_like , np.array_like to make an array of the same size whenever possible\n",
    "# \n",
    "# (4) when/if decide to normalize it do it for the entire stack not on a per image basis --> don't lose dynamic range\n",
    "# \n",
    "# (6) what was the image from the  text that you sent me? --> x = (,) can do np.zeros([*x])\n",
    "# \n",
    "# (7) processing: convolutions?, mean, median, sum (not the same bc if neuron is bigger the sum will be bigger but\n",
    "# not a big deal if on a per neuron basis)?, thresholding?, time series?\n",
    "# \n",
    "# (8) Is there a reason median across time takes so much longer than mean or sum across time? y\n",
    "\n",
    "# IMPORTANT COMMENTS!!!\n",
    "# # The median array is not the same as the mean or sum array\n",
    "# But the mean and sum array for percentile cutoffs are the same --> DUHHHHH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: when wanting to save the results to a .npy file do:\n",
    "# np.save('lab_200_masks_no_time_series_percentile_87', masks_200_percentile_87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rewrite section 1 to be encapsulated by one function???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy\n",
    "import skimage.io as skimage\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from scipy import signal\n",
    "from scipy.ndimage import measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param lab_names: a list of all of the lab names as strings that appear in our file names i.e. '_p200'\n",
    "@param files: a glob of files\n",
    "\n",
    "@return lab_names_to_files: a defaultdict where the lab names are the keys and all of the file names that fall into that lab\n",
    "are the values\n",
    "'''\n",
    "def seperate_file_names_by_lab(lab_names, files):\n",
    "    lab_names_to_files = defaultdict(list)\n",
    "    \n",
    "    for file in files:\n",
    "        lab_name_found = False\n",
    "        for lab_name in lab_names:\n",
    "            if re.search(lab_name, file):\n",
    "                lab_names_to_files[lab_name].append(file)\n",
    "                lab_name_found = True\n",
    "        if not lab_name_found:\n",
    "            print('error file name: ' + file + ' not found in lab names')\n",
    "            \n",
    "    return lab_names_to_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INITIAL_DATA_GLOB = glob('/Users/sabera.talukder/Desktop/anithaTestData/*.tiff')\n",
    "files = sorted(INITIAL_DATA_GLOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_P200_FILES = 8000\n",
    "NUM_P300_FILES = 2250\n",
    "lab_names = ['_p200', '_p300']\n",
    "\n",
    "# split data files based on lab name\n",
    "lab_names_to_files = seperate_file_names_by_lab(lab_names, files)\n",
    "\n",
    "# assert just checks to make sure the statement is true and if it is not returns the comment to its right\n",
    "assert len(lab_names_to_files['_p200']) == NUM_P200_FILES, 'missing files'\n",
    "assert len(lab_names_to_files['_p300']) == NUM_P300_FILES, 'missing files'\n",
    "\n",
    "files_200 = np.array(lab_names_to_files['_p200'])\n",
    "files_300 = np.array(lab_names_to_files['_p300'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param file_name: a name of one file\n",
    "\n",
    "@return int_list_C_Z_T_P: a list containing the integer values within the file name in the order C, Z, T, P\n",
    "\n",
    "@notes:\n",
    "-r signifies that the following argument is a string\n",
    "-the '\\d+' signifies that we are looking for a digit\n",
    "'''\n",
    "def find_integers_in_file_name(file_name):\n",
    "    string_list_C_Z_T_P = re.findall(r'\\d+', file_name)\n",
    "    int_list_C_Z_T_P = list(map(int, string_list_C_Z_T_P))\n",
    "    return int_list_C_Z_T_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param file_names: a numpy array of file names\n",
    "\n",
    "@return True / False: returns a True or False depending on whether or not the files in the numpy array are sorted by\n",
    "their time value\n",
    "'''\n",
    "def verify_files_sorted_by_time(file_names):\n",
    "    for idx in range(0, len(file_names)-1):\n",
    "        first_file_vals = find_integers_in_file_name(file_names[idx])\n",
    "        second_file_vals = find_integers_in_file_name(file_names[idx + 1])\n",
    "        if not first_file_vals[2] < second_file_vals[2]:\n",
    "            print('Time values are not in increasing order. The idx this occured at is: ' + str(idx))\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(verify_files_sorted_by_time(files_200))\n",
    "print(verify_files_sorted_by_time(files_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param file_names: a numpy array of file names\n",
    "\n",
    "@return: returns a 3D numpy array containing the images in the\n",
    "correct time series order. Each image is a 2d numpy array within the 3D numpy array.\n",
    "'''\n",
    "def convert_file_names_to_img_arr(file_names):\n",
    "    return np.array([skimage.imread(f) for f in file_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_200 = convert_file_names_to_img_arr(files_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_300 = convert_file_names_to_img_arr(files_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE_200 = imgs_200.shape[1:]\n",
    "IMG_SHAPE_300 = imgs_300.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param neuron_mask_path: Is the path to the regions.json file that contains the information about all of the neuron\n",
    "masks\n",
    "\n",
    "@return regions: regions is a list of dictionaries. The length of regions (i.e. the # of dicts) is the # of pixels to\n",
    "be filled in for each neuron. The key for every dict is 'coordinates' and the values are the pixel coordinates for\n",
    "each mask.\n",
    "'''\n",
    "def read_in_neuron_masks(neuron_mask_path):\n",
    "    with open(neuron_mask_path) as file:\n",
    "        regions = json.load(file)\n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_200 = read_in_neuron_masks('neurofinder.02.00/regions/regions.json')\n",
    "regions_300 = read_in_neuron_masks('neurofinder.03.00/regions/regions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param coords: A list of all of the pixel values in the form [[x1,y1],[x2,y2],...]\n",
    "@param dims: A tuple of the 2d array dimensions of the mask, where the pixel coordinates will be filled in.\n",
    "\n",
    "@ return mask: a 2d zeros numpy array where the shape of a neuron is filled in with pixel values of 1.\n",
    "'''\n",
    "def fill_in_pixel_vals(coords, dims):\n",
    "    mask = np.zeros(dims)\n",
    "    for coord in coords:\n",
    "        mask[coord[0], coord[1]] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 512\n"
     ]
    }
   ],
   "source": [
    "print(*IMG_SHAPE_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param regions: a list of dicts, each dict contains all of the coordinate values for one neuron mask\n",
    "@param img_shape_tuple: a tuple of the 2d array dimensions of the mask\n",
    "\n",
    "@return mask_array: a 3d array with dimensions: (# of neurons, x dim of mask, y dim of mask). Each 2D array within\n",
    "the 3D array is the mask for one neuron, where neuron pixels = 1 and rest of array = 0.\n",
    "\n",
    "@notes:\n",
    "-this function calls fill_in_pixel_vals(coords, dims) to fill in the pixel vals\n",
    "'''\n",
    "def go_from_dict_vals_to_masks(regions, img_shape_tuple):\n",
    "    KEY_FOR_MASK_DICTS = 'coordinates'\n",
    "    # the *img_shape_tuple just makes it so that we can take the dimensions without unpacking the tuple like:\n",
    "    # img_shape_tuple[0], img_shape_tuple[1]\n",
    "    mask_array = np.zeros([len(regions), *img_shape_tuple])\n",
    "    \n",
    "#     TODO pick a better name than dictionary\n",
    "    for idx, dictionary in enumerate(regions):\n",
    "        mask_array[idx, :, :] = fill_in_pixel_vals(dictionary[KEY_FOR_MASK_DICTS],img_shape_tuple)\n",
    "    return mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_200 = go_from_dict_vals_to_masks(regions_200, IMG_SHAPE_200)\n",
    "masks_300 = go_from_dict_vals_to_masks(regions_300, IMG_SHAPE_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a namedtuple to be used in the get_neuron_mask_info(total_mask_array) function\n",
    "neuron_mask = namedtuple('neuron_mask', ['num_neuron', 'num_pixels', 'x_min', 'y_min', 'x_max', 'y_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param total_mask_array: a 3d array where each 2d slice is a mask for one neuron in that stack.\n",
    "\n",
    "@return neuron_info: a list of namedtuples containing the index where the neuron appeared in the total mask, the\n",
    "number of pixels in that mask, then x_min, y_min, x_max, y_max. The coordinates allow us to create a neuron bounding \n",
    "box\n",
    "'''\n",
    "def get_neuron_mask_info(total_mask_array):\n",
    "    neuron_info = []\n",
    "    for idx, mask in enumerate(total_mask_array):\n",
    "        # returns the unique pixel values, and the number of times each of those pixel values appear in the img\n",
    "        unique, counts = np.unique(mask, return_counts = True)\n",
    "        # returns an array with x indicies, and an array with y indicies wherever the pixel was == 1\n",
    "        where_one = np.where(mask == 1)\n",
    "        neuron = neuron_mask(num_neuron=idx, num_pixels = counts[-1], x_min = np.min(where_one[0]), \\\n",
    "                             y_min = np.min(where_one[1]), x_max = np.max(where_one[0]), y_max = np.max(where_one[1]))\n",
    "        neuron_info.append(neuron)\n",
    "    return neuron_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_200_info = get_neuron_mask_info(masks_200)\n",
    "masks_300_info = get_neuron_mask_info(masks_300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='+3'>\n",
    "^ UP until that point is processing and generating DATA\n",
    "    <br>\n",
    "    <br>\n",
    "    We will call the previous section: Section 1\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param filter_type: a string of the value 'median', 'mean', or 'sum'. This is the metric that we will use to compare\n",
    "neurons to one another.\n",
    "\n",
    "@param: neuron_2d_array: the 2d array that contains the true image values, but only for the pixels that count as being\n",
    "part of the neuron\n",
    "\n",
    "@return: returns float of the median, mean, or sum. OR prints an error if you didn't pass a valid filer type\n",
    "'''\n",
    "def neuron_image_evaluation(filter_type, neuron_2d_array):\n",
    "    if filter_type == 'median':\n",
    "        return np.median(neuron_2d_array)\n",
    "    elif filter_type == 'mean':\n",
    "        return np.mean(neuron_2d_array)\n",
    "    elif filter_type == 'sum':\n",
    "        return np.sum(neuron_2d_array)\n",
    "    else:\n",
    "        print('error did not pass a valid string argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param mask_info: the list of namedtuples that contains the neuron index in the mask array, the neuron's array, and\n",
    "the bounding box information\n",
    "\n",
    "@param total_mask_array: a 3d array of all of the masks for a full stack (#neurons, x_dim of masks, y_dim of masks)\n",
    "\n",
    "@param img_stack: a 3d array of all of the imgs (#time_steps, x_dim of imgs, y_dim of imgs)\n",
    "\n",
    "@param how_to_evaluate_neuron: which is the 'median', 'mean', 'sum' that the neuron_image_evaluation() requires\n",
    "\n",
    "@return neuron_across_time_series: a 2d array with size (# of neurons, # of imgs in the time series). Each value in\n",
    "the array is the median/mean/or sum of the pixels that fill the neuron bounding box in that img\n",
    "\n",
    "@note:\n",
    "-the x_dim of masks = the x_dim of imgs, the y_dim of masks = the y_dim of imgs\n",
    "'''\n",
    "def neuron_vals_across_time_series(mask_info, total_mask_array, img_stack, how_to_evaluate_neuron):\n",
    "    neuron_across_time_series = np.zeros([total_mask_array.shape[0], img_stack.shape[0]])\n",
    "    \n",
    "    for mask_idx, neuron in enumerate(mask_info):\n",
    "        cur_info = mask_info[mask_idx]\n",
    "        mask = total_mask_array[mask_idx, cur_info.x_min : cur_info.x_max, cur_info.y_min : cur_info.y_max]\n",
    "        \n",
    "        for time_idx, img in enumerate(img_stack):\n",
    "            img_segment = img[cur_info.x_min : cur_info.x_max, cur_info.y_min : cur_info.y_max]\n",
    "            neuron = mask * img_segment\n",
    "            m_m_or_s_val = neuron_image_evaluation(how_to_evaluate_neuron, neuron)\n",
    "            neuron_across_time_series[mask_idx, time_idx] = m_m_or_s_val\n",
    "            \n",
    "    return neuron_across_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param neuron_and_time_stack: 2d array with dims (# of neurons, # of imgs in the time series)\n",
    "\n",
    "@param percentile: a int or float that signifies the percentile cutoff we will apply to each neuron's time series\n",
    "\n",
    "@return percentile_val_per_neuron: a 1d array (# neurons, 1) with the actual percentile value per neuron. i.e. if we\n",
    "want the 85th percentile for the median that might coorespond to pixel value of 13 for one neuron across its time\n",
    "series\n",
    "'''\n",
    "def compute_percentile_per_neuron(neuron_and_time_stack, percentile):\n",
    "    NUM_NEURONS = neuron_and_time_stack.shape[0]\n",
    "    percentile_val_per_neuron = np.zeros([NUM_NEURONS, 1])\n",
    "    for row in range(0, NUM_NEURONS):\n",
    "        percentile_val = np.percentile(neuron_and_time_stack[row, :], percentile)\n",
    "        percentile_val_per_neuron[row, 0] = percentile_val\n",
    "    return percentile_val_per_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param percentile_vals: a 1d array (# neurons, 1) with the actual percentile value per neuron\n",
    "\n",
    "@param neuron_across_time_series: a 2d array with size (# of neurons, # of imgs in the time series). Each value in \n",
    "the array is the median/mean/or sum of the pixels that fill the neuron bounding box in that img\n",
    "\n",
    "@return neuron_mask_present_in_img: a 2d array with size (# of neurons, # of imgs in the time series) [SAME size as\n",
    "the neuron_across_time_series array] if the value in the array is 1 it signifies that that neuron is above the Xth\n",
    "percentile across that neuron's time series, if the value in the array is 0 it signififes that that neuron is below\n",
    "the Xth percentile for that neuron's time series.\n",
    "'''\n",
    "def array_where_neuron_val_above_percentile(percentile_vals, neuron_across_time_series):\n",
    "    NUM_NEURONS = percentile_vals.shape[0] # = neuron_across_time_series.shape[0]\n",
    "    NUM_IMGS_IN_TIME_SERIES = neuron_across_time_series.shape[1]\n",
    "    neuron_mask_present_in_img = np.zeros_like(neuron_across_time_series)\n",
    "    for row in range(0, NUM_NEURONS):\n",
    "        percential_val = percentile_vals[row, 0]\n",
    "        for col in range(0, NUM_IMGS_IN_TIME_SERIES):\n",
    "            if neuron_across_time_series[row, col] > percential_val:\n",
    "                neuron_mask_present_in_img[row, col] = 1\n",
    "    return neuron_mask_present_in_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param median_array: 2d array of dims (# of neurons, # of imgs in the time series). 1 values in array indicate that\n",
    "the median is above the Xth percentile\n",
    "\n",
    "@param mean_array: 2d array of dims (# of neurons, # of imgs in the time series). 1 values in array indicate that\n",
    "the mean is above the Xth percentile\n",
    "\n",
    "@return above_percentile_in_med_mean: returns 2d array of dims (# of neurons, # of imgs in the time series) where the\n",
    "median array has been multipled by the mean array. Since the arrays are all 0s or 1s if we multiply them together \n",
    "only the neuron values that are above the Xth percentile for both metrics will be represented\n",
    "'''\n",
    "def combine_median_mean(median_array, mean_array):\n",
    "    above_percentile_in_med_mean = median_array * mean_array\n",
    "    return above_percentile_in_med_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param neuron_vs_time_series: 2d array dim (# neurons, total # of time stamps). Demonstrates which neurons are high\n",
    "during which time series\n",
    "\n",
    "@param total_time_filter_len: The length of time series in which we want to check how many times a neuron went high.\n",
    "If input an even number i.e. n will actually look at the total_time_fitler_len of n + 1. I.e. 2 --> 3, 4 --> 5.\n",
    "\n",
    "@return time_filtered_neuron_vs_time_series: returns a 2d array dim (# neurons, total # of time stamps). Demonstrates \n",
    "which neurons are high during which time series with the applied time filter\n",
    "\n",
    "@note:\n",
    "-if input total_time_filter_len == 0 or 1 just returns back neuron_vs_time_series --> because values of 0, 1 imply\n",
    "that you do not want your data to be time filtered\n",
    "'''\n",
    "def time_filter(neuron_vs_time_series, total_time_filter_len):\n",
    "    \n",
    "    if total_time_filter_len == 0 or total_time_filter_len == 1:\n",
    "        return neuron_vs_time_series\n",
    "    \n",
    "    time_filtered_neuron_vs_time_series = np.zeros_like(neuron_vs_time_series)\n",
    "    NUM_NEURONS = neuron_vs_time_series.shape[0]\n",
    "    TOTAL_TIME_SERIES = neuron_vs_time_series.shape[1]\n",
    "    len_on_either_side = int(total_time_filter_len/2 +.5)\n",
    "    \n",
    "    for neuron in range(0, NUM_NEURONS):\n",
    "        for time_stamp in range(0, TOTAL_TIME_SERIES):\n",
    "            if time_stamp - len_on_either_side >= 0:\n",
    "                in_bounds_to_left = True\n",
    "            else:\n",
    "                in_bounds_to_left = False\n",
    "                \n",
    "            if time_stamp + len_on_either_side <= TOTAL_TIME_SERIES:\n",
    "                in_bounds_to_right = True\n",
    "            else:\n",
    "                in_bounds_to_right = False\n",
    "\n",
    "            \n",
    "            # out of bounds on left, in bounds on right\n",
    "            if not in_bounds_to_left & in_bounds_to_right:\n",
    "                segment_to_check = neuron_vs_time_series[neuron][0 : time_stamp+len_on_either_side]\n",
    "                # there are multiple values of 1 for this neuron in this time window so this value should stay 1\n",
    "                if np.count_nonzero(segment_to_check) > 1:\n",
    "                    if neuron_vs_time_series[neuron, time_stamp] == 1:\n",
    "                        time_filtered_neuron_vs_time_series[neuron, time_stamp] = 1\n",
    "                # there is only one value of 1 for this neuron in this time window so this value should get set to 0\n",
    "                else:\n",
    "                    time_filtered_neuron_vs_time_series[neuron, time_stamp] = 0\n",
    "                                         \n",
    "            # in bounds on left, out of bounds on right\n",
    "            if not in_bounds_to_right & in_bounds_to_left:\n",
    "                segment_to_check = neuron_vs_time_series[neuron][time_stamp-len_on_either_side :]\n",
    "                # there are multiple values of 1 for this neuron in this time window so this value should stay 1\n",
    "                if np.count_nonzero(segment_to_check) > 1:\n",
    "                    if neuron_vs_time_series[neuron, time_stamp] == 1:\n",
    "                        time_filtered_neuron_vs_time_series[neuron, time_stamp] = 1\n",
    "                # there is only one value of 1 for this neuron in this time window so this value should get set to 0\n",
    "                else:\n",
    "                    time_filtered_neuron_vs_time_series[neuron, time_stamp] = 0\n",
    "            \n",
    "            # in bounds on left, in bounds on right\n",
    "            if in_bounds_to_left & in_bounds_to_right:\n",
    "                segment_to_check = neuron_vs_time_series[neuron][time_stamp-len_on_either_side : time_stamp+len_on_either_side]\n",
    "                # there are multiple values of 1 for this neuron in this time window so this value should stay 1\n",
    "                if np.count_nonzero(segment_to_check) > 1:\n",
    "                    if neuron_vs_time_series[neuron, time_stamp] == 1:\n",
    "                        time_filtered_neuron_vs_time_series[neuron, time_stamp] = 1\n",
    "                # there is only one value of 1 for this neuron in this time window so this value should get set to 0\n",
    "                else:\n",
    "                    time_filtered_neuron_vs_time_series[neuron, time_stamp] = 0\n",
    "    \n",
    "    return time_filtered_neuron_vs_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all_masks = return_total_masks(np.transpose(combined_percentiles), total_mask_array, img_stack)\n",
    "\n",
    "@param array_masks_per_img: 2d array of dims (# of imgs in the time series, # of neurons). i.e. the transpose of what\n",
    "the combine_median_mean() returns. \n",
    "\n",
    "@param all_masks: 3d array that contains all of the masks for an image stack. (# neurons, x_dim, y_dim)\n",
    "\n",
    "@param all_imgs: 3d array that contains all of the images in an image stack (# of images in time series, x_dim, y_dim)\n",
    "\n",
    "@return total_masks_for_imgs: 3c array of dims (# of images in time series, x_dim, y_dim). Each slice in this 3d\n",
    "array contains the mask with neurons above the Xth percentile for each image in the time series\n",
    "'''\n",
    "def return_total_masks(array_masks_per_img, all_masks, all_imgs):\n",
    "    NEURON_NUM = all_masks.shape[0]\n",
    "    TIME_SERIES_NUM = all_imgs.shape[0]\n",
    "    IMG_X_DIM = all_imgs.shape[1] #This is the same dimension as all_masks.shape[1]\n",
    "    IMG_Y_DIM = all_imgs.shape[2] #This is the same dimension as all_masks.shape[2]\n",
    "    total_masks_for_imgs = np.zeros([TIME_SERIES_NUM, IMG_X_DIM, IMG_Y_DIM])\n",
    "    \n",
    "    for row in range(0, TIME_SERIES_NUM):\n",
    "        total_mask = np.zeros([IMG_X_DIM, IMG_Y_DIM])\n",
    "        for col in range(0, NEURON_NUM):\n",
    "            if array_masks_per_img[row, col] == 1:\n",
    "                total_mask = total_mask + all_masks[col, :, :]\n",
    "        total_masks_for_imgs[row, :, :] = total_mask\n",
    "    return total_masks_for_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='+3'>\n",
    "^ UP until that point extracting masks based on a percentile value\n",
    "    <br>\n",
    "    <br>\n",
    "    That was Section 2.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@params neuron_vs_time_series: a 2d array of dims (# of neurons, # of imgs in the time series) The arrays is all 0s \n",
    "or 1s. 1 indicates neuron is above Xth percentile in that time slice\n",
    "\n",
    "@return True / False: returns true if every neuron is high in at least 1 image in the time series. returns false if\n",
    "there is a neuron that is not present across a time series.\n",
    "\n",
    "@note:\n",
    "-it is a problem if this check returns false, because every neuron should be high at least once if it belongs in the\n",
    "data set.\n",
    "'''\n",
    "    \n",
    "def neuron_high_at_least_once_in_time_series(neuron_vs_time_series):\n",
    "    for neuron_num in range(0, neuron_vs_time_series.shape[0]):\n",
    "        # there is a neuron that is not present even once\n",
    "        if not np.isin(1, neuron_vs_time_series[neuron_num, :]):\n",
    "            print('there is a neuron that is not high at least once' + str(neuron_num))\n",
    "            return False\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param percentile_selectivity: int or float that demonstrates what percentile selectivity we are going to cutoff at\n",
    "\n",
    "@param time_filter_length: an int that gives the total number of time series we will filter against. If pass 0 or 1 \n",
    "will not compute a time filter. Change to be greater or equal to 2 to get a time filtered result.\n",
    "\n",
    "@param mask_info: a list of namedtuples containing the index where the neuron appeared in the total mask, the\n",
    "number of pixels in that mask, then x_min, y_min, x_max, y_max. The coordinates allow us to create a neuron bounding \n",
    "box\n",
    "\n",
    "@param total_mask_array: a 3d array dims (# neurons, x_dim, y_dim) each slice of the 3d array contains a mask for 1\n",
    "neuron\n",
    "\n",
    "@param img_stack: a 3d array dims (# time steps, x_dim, y_dim) each slice of the 3d array contains an in order image\n",
    "from the time series\n",
    "'''\n",
    "def mask_for_each_img_in_time_series(percentile_selectivity, time_filter_length, mask_info, total_mask_array, img_stack):\n",
    "    \n",
    "    TOTAL_NUM_TIME_STEPS = img_stack.shape[0]\n",
    "    TOTAL_NUM_NEURONS = total_mask_array.shape[0]\n",
    "\n",
    "    neuron_med_across_time = neuron_vals_across_time_series(mask_info, total_mask_array, img_stack, 'median')\n",
    "    neuron_mean_across_time = neuron_vals_across_time_series(mask_info, total_mask_array, img_stack, 'mean')\n",
    "\n",
    "    percentile_val_per_neuron_med = compute_percentile_per_neuron(neuron_med_across_time, percentile_selectivity)\n",
    "    percentile_val_per_neuron_mean = compute_percentile_per_neuron(neuron_mean_across_time, percentile_selectivity)\n",
    "\n",
    "    neuron_med_above_percentile = array_where_neuron_val_above_percentile(percentile_val_per_neuron_med, neuron_med_across_time)\n",
    "    neuron_mean_above_percentile = array_where_neuron_val_above_percentile(percentile_val_per_neuron_mean, neuron_mean_across_time)\n",
    "    \n",
    "    combined_percentiles = combine_median_mean(neuron_med_above_percentile, neuron_mean_above_percentile)\n",
    "    \n",
    "    if neuron_high_at_least_once_in_time_series(combined_percentiles) == False:\n",
    "        print('error, some neurons are not present even before time filtering')\n",
    "        \n",
    "    time_filtered_combined_percentile = time_filter(combined_percentiles, time_filter_length)\n",
    "    \n",
    "    if neuron_high_at_least_once_in_time_series(time_filtered_combined_percentile) == False:\n",
    "        print('error, some neurons are not present AFTER time filtering')\n",
    "    \n",
    "    all_masks = return_total_masks(np.transpose(time_filtered_combined_percentile), total_mask_array, img_stack)\n",
    "    \n",
    "    return all_masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make sure the time component step of what I am doing actually works!!!\n",
    "#  --> should be working!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_selectivity = 87\n",
    "time_filter_length = 0\n",
    "mask_info = masks_200_info\n",
    "total_mask_array = masks_200\n",
    "img_stack = imgs_200\n",
    "\n",
    "\n",
    "\n",
    "TOTAL_NUM_TIME_STEPS = img_stack.shape[0]\n",
    "TOTAL_NUM_NEURONS = total_mask_array.shape[0]\n",
    "\n",
    "neuron_med_across_time = neuron_vals_across_time_series(mask_info, total_mask_array, img_stack, 'median')\n",
    "neuron_mean_across_time = neuron_vals_across_time_series(mask_info, total_mask_array, img_stack, 'mean')\n",
    "\n",
    "percentile_val_per_neuron_med = compute_percentile_per_neuron(neuron_med_across_time, percentile_selectivity)\n",
    "percentile_val_per_neuron_mean = compute_percentile_per_neuron(neuron_mean_across_time, percentile_selectivity)\n",
    "\n",
    "neuron_med_above_percentile = array_where_neuron_val_above_percentile(percentile_val_per_neuron_med, neuron_med_across_time)\n",
    "neuron_mean_above_percentile = array_where_neuron_val_above_percentile(percentile_val_per_neuron_mean, neuron_mean_across_time)\n",
    "    \n",
    "combined_percentiles = combine_median_mean(neuron_med_above_percentile, neuron_mean_above_percentile)\n",
    "    \n",
    "if neuron_high_at_least_once_in_time_series(combined_percentiles) == False:\n",
    "    print('error, some neurons are not present!')\n",
    "        \n",
    "time_filtered_combined_percentile = time_filter(combined_percentiles, time_filter_length)\n",
    "\n",
    "if neuron_high_at_least_once_in_time_series(combined_percentiles) == False:\n",
    "    print('error, some neurons are not present!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_filter_length = 5\n",
    "\n",
    "time_filtered_combined_percentile_5 = time_filter(combined_percentiles, time_filter_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_0, counts_0 = np.unique(time_filtered_combined_percentile, return_counts=True)\n",
    "unique_5, counts_5 = np.unique(time_filtered_combined_percentile_5, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [1429646  146354]\n",
      "[0. 1.] [1454635  121365]\n"
     ]
    }
   ],
   "source": [
    "print(unique_0, counts_0)\n",
    "print(unique_5, counts_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(time_filtered_combined_percentile_5[0][7870:7900])\n",
    "print(time_filtered_combined_percentile[0][7870:7900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in between\n"
     ]
    }
   ],
   "source": [
    "all_masks_0 = return_total_masks(np.transpose(time_filtered_combined_percentile), total_mask_array, img_stack)\n",
    "print('in between')\n",
    "all_masks_5 = return_total_masks(np.transpose(time_filtered_combined_percentile_5), total_mask_array, img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c431fc0b8>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(all_masks_0[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c37183080>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(all_masks_5[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(303, 0), dtype=float64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[x_min:x_max, y_min:y_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = []\n",
    "for row in range(0, time_filter_0[0].shape[0]):\n",
    "    for col in range(0, time_filter_0[0].shape[1]):\n",
    "        if not time_filter_0[0][row, col] == time_filter_5[0][row, col]:\n",
    "            indicies.append([row, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = indicies[0][0]\n",
    "x_max = indicies[0][0]\n",
    "\n",
    "y_min = indicies[0][1]\n",
    "y_max = indicies[0][1]\n",
    "\n",
    "for item in range(0, len(indicies)):\n",
    "    if indicies[item][0] > x_max:\n",
    "        x_max = indicies[item][0]\n",
    "    if indicies[item][0] < x_min:\n",
    "        x_min = indicies[item][0]\n",
    "        \n",
    "    if indicies[item][1] > y_max:\n",
    "        y_max = indicies[item][0]\n",
    "    if indicies[item][1] < y_min:\n",
    "        y_min = indicies[item][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 434 434 397\n"
     ]
    }
   ],
   "source": [
    "print(x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(time_filter_5, time_filter_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONCE time component is all fixed --> make a movie then I am done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_200_percentile_87 = temp_which_percentile(87, masks_200_info, masks_200, imgs_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_300_percentile_87 = temp_which_percentile(87, masks_300_info, masks_300, imgs_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_total_mask_over_img_slice(total_masks, all_imgs, img_idx):\n",
    "    plt.imshow(all_imgs[img_idx,:,:], cmap = 'gray')\n",
    "    Mask = np.ma.masked_array(total_masks[img_idx, :, :] == 0, total_masks[img_idx, :, :])\n",
    "    plt.imshow(Mask, cmap = 'hsv',alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b7201048cefa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mIMG_TO_PLOT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2158\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All Possible Masks Overlaid on Image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_300\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIMG_TO_PLOT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "IMG_TO_PLOT = 2158\n",
    "plt.figure(figsize=(30, 50))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"All Possible Masks Overlaid on Image\", fontsize=25)\n",
    "plt.imshow(imgs_300[IMG_TO_PLOT], cmap = 'gray')\n",
    "Mask = np.ma.masked_array(masks_300.sum(axis=0) == 0, masks_300.sum(axis=0))\n",
    "plt.imshow(Mask, cmap = 'hsv', alpha = .5)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Masks at 87th Percentile Overlaid on Image\", fontsize=25)\n",
    "plot_total_mask_over_img_slice(all_masks_0[0], imgs_300, IMG_TO_PLOT)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Masks at 87th Percentile Overlaid on Image\", fontsize=25)\n",
    "plot_total_mask_over_img_slice(all_masks_5[0], imgs_300, IMG_TO_PLOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fxn to save the whole movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "x = np.arange(0, 490, 1)\n",
    "y = np.arange(0, 498, 1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "nFrames = imgs_300.shape[0]\n",
    "\n",
    "# # Set up plotting\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()  \n",
    "\n",
    "# Animation function\n",
    "def animate(i): \n",
    "    z = imgs_300[i,:,:]\n",
    "    cont = plt.contourf(X, Y, z)\n",
    "    \n",
    "    return cont\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=nFrames)\n",
    "\n",
    "mywriter = animation.FFMpegWriter()\n",
    "anim.save('animation.mp4',writer=mywriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
